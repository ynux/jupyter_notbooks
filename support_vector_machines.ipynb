{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "\n",
    "\n",
    "\n",
    "## Problem to solve: Do you think you can tell / heaven from hell?\n",
    "\n",
    "* supervised learning\n",
    "\n",
    "* classification of points in a space of dimension d: Find hyperplane (dimension d-1) to separate the points\n",
    "\n",
    "* More formally: \n",
    "    - input: $\\vec{x} = [x_1, x_2, \\dots , x_d] $ with label $y_1$\n",
    "    - find weights $\\vec{w} = [w_1, w_2, \\dots , w_d] $ and threshold $\\theta$ \n",
    "    - output: if $\\vec{w}\\cdot\\vec{x} > \\theta$ then +1, if $\\vec{w}\\cdot\\vec{x} < \\theta$ then -1 \n",
    "    - $\\vec{w}$ defines a hyperplane\n",
    "    \n",
    "Let's plot it: d=2. \n",
    "The \"hyperplane\" becomes a straight line seperating the differently colored points. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lightning import Lightning\n",
    "import math\n",
    "from numpy import random, asarray, sqrt, arctan2, pi, clip, concatenate\n",
    "#from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lgn = Lightning(ipython=True, host='http://public.lightning-viz.org')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "halfn = 5\n",
    "n = 2*halfn\n",
    "mean = 4\n",
    "# sample around zero\n",
    "x_1_0 = random.randn(n)\n",
    "x_2_0 = random.randn(n)\n",
    "# sample around (mean,mean)\n",
    "x_1_1 = random.randn(n) + mean\n",
    "x_2_1 = random.randn(n) + mean\n",
    "# concat both samples\n",
    "x_1 = concatenate([x_1_0,x_1_1])\n",
    "x_2 = concatenate([x_2_0,x_2_1])\n",
    "label_0 = [0] * (n)\n",
    "label_1 = [1] * (n)\n",
    "labels = concatenate([label_0,label_1])\n",
    "lgn.scatter(x_1, x_2, group=labels,  zoom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Approach:\n",
    "Find mean / median, connect with a line, draw line perpendicular at half distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sigma=2\n",
    "x_1_new0 = sigma*random.randn(n)\n",
    "x_1_new1 = sigma*random.randn(n) + mean\n",
    "x_2_new0 = sigma*random.randn(n)\n",
    "x_2_new1 = sigma*random.randn(n) + mean\n",
    "x_1_all = concatenate([x_1,x_1_new0,x_1_new1])\n",
    "x_2_all = concatenate([x_2,x_2_new0,x_2_new1])\n",
    "label_0 = [0] * (n)\n",
    "label_1 = [1] * (n)\n",
    "label_new = [2] * (2*n)\n",
    "labels_new = concatenate([label_0,label_1,label_new])\n",
    "\n",
    "lgn.scatter(x_1_all, x_2_all,  group=labels_new, zoom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perceptrons \n",
    "\n",
    "*  But we know how to do that already, we learned perceptrons, right? [https://appsworks.td.teradata.com/display/BBB/13th+July+2016+%3A+Perceptron]\n",
    "\n",
    "### and their problems\n",
    "* Data is not linearly separable -> doesn’t converge\n",
    "* Hyperplane found may not be the “best” - just any that separates the points\n",
    "\n",
    "## Best Hyperplane\n",
    "maximize the margin - find the broadest road between the dot clouds \n",
    "\n",
    "![title](broken.png)\n",
    "Figure: MaxMargin\n",
    "\n",
    "Only the closest points count - \"support vectors\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Ng Approach : Start with the utility function\n",
    "\n",
    "(Modified from the one in logistic regression)\n",
    "\n",
    "![title](broken.png)\n",
    "\n",
    "\"In case this equation looks a bit unfamiliar, this is because previously we had a minus sign ... \"\n",
    "or you didn't do the weeks 1 - 6 of the course. And aren't familiar with logistic regression etc.\n",
    "Even with this, he dedicates 19 min video to \"The Mathematics Behind the Large Margin Classifier\".\n",
    "\n",
    "But let's have a look at it.\n",
    "C is the regularization parameter. Assume for now that it is big, say, 100000. Then you really want to get the first term to zero. \n",
    "What are cost1, cost0? \n",
    "![title](broken.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main thing is: Classify all correctly, and it's zero.\n",
    "Second term: Forces \"line to turn\" until the margin is maximized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case: Not linearly separable\n",
    "\n",
    "Transform to higher dimension, solve there, transform back\n",
    "### Problems:\n",
    "* Calculation gets expensive\n",
    "* The transformed hyperplane is crazy complex, unusable\n",
    "* Overfitting\n",
    "\n",
    "Kerneltrick helps with this - If I get this right, no calculations, much nicer hyperplane, but overfitting is still a problem.\n",
    "\n",
    "Or allow misclassification - find a balance between misclassification punishment and widest margin by chosing C.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nl=300\n",
    "inner=2\n",
    "xnl_1 = 2*random.randn(nl)\n",
    "#print(len(x_0))\n",
    "xnl_2 = 2*random.randn(nl) \n",
    "#print(len(x))\n",
    "labels_nl=[1]*nl\n",
    "for i in range(nl):\n",
    "    if ( xnl_1[i]**2 + xnl_2[i]**2 ) < inner:\n",
    "        labels_nl[i] = 0\n",
    "\n",
    "lgn.scatter(xnl_1, xnl_2,  group=labels_nl, zoom=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this as a mountain, and cut the top.\n",
    "\n",
    "(Average would not work at all here, same point!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dirty Data ?!\n",
    "\n",
    "Remember that only the points closest to the boundary count (typically, d+1 points). What does this mean for robustness? \n",
    "Our naive approach works better here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM vs Logistic Regression (Ng)\n",
    "\n",
    "* A. d dimension (number of features), n number of samples: \n",
    "d large compared to n: Use logistic regression, or SVM without kernel. Example: Spam Classification, d=10000, n=1000.\n",
    "* B. d is small, n medium sized: Use SVM with linear / Gaussian kernel\n",
    "* C. d is small, n is big: SVM would run long, find more features and back to case A\n",
    "\n",
    "linear regression and SVM without kernel are pretty similar for most combinations of d and n\n",
    "\n",
    "SVM is strong with Kernels for d<1000, n=1000 up to n=50000\n",
    "\n",
    "Or use neural network - takes some training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of Support-Vector Machines (Segaran)\n",
    "\n",
    "* Classifying facial expressions\n",
    "* Detecting intruders using military datasets\n",
    "* Predicting the structure of proteins from their sequences\n",
    "* Handwriting recognition\n",
    "* Determining the potential for damage during earthquakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation: How to find that minimum\n",
    "\n",
    "\n",
    "quadratic programming, but not well suited to large datasets because (normally) keeps all in memory. Better use gradient descent and keep data on disc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "#lgn.scatter(x_all, y_all,  group=labels, zoom=False)\n",
    "X = [[0,0] for x in range(2*n)]\n",
    "for i in range(2*n):\n",
    "    X[i][0]=x_1[i]\n",
    "    X[i][1]=x_2[i]\n",
    "    \n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X, labels)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[0, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[mean,mean]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[mean/2-0.8,mean/2-0.6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lgn.scatter(xnl_1, xnl_2,  group=labels_nl, zoom=False)\n",
    "print(2*nl)\n",
    "X_nl = [[0,0] for x in range(nl)]\n",
    "for i in range(nl):\n",
    "    X_nl[i][0]=xnl_1[i]\n",
    "    X_nl[i][1]=xnl_2[i]\n",
    "    \n",
    "\n",
    "clf_nl = svm.SVC()\n",
    "clf_nl.fit(X_nl, labels_nl)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[0, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.predict([[2, 2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sources and Literature\n",
    "\n",
    "* https://de.wikipedia.org/wiki/Support_Vector_Machine \n",
    "\n",
    "* https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "* Mining Massive Datasets, http://www.mmds.org/ , book, 12.7\n",
    "\n",
    "* Toby Segaran, Programming Collective Intelligence, chapter 9\n",
    " \n",
    "* Andrew Ng, Coursera, week 7; e.g. http://www.holehouse.org/mlclass/12_Support_Vector_Machines.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
